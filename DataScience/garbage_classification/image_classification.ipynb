{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification (CNN - keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try the process of implementing CNN with Keras to classify images \n",
    "# 1. import useful packages \n",
    "# 2. load the data before visualize and preprocess it \n",
    "# 3. try a simplt CNN moodel and then evaluate its performances \n",
    "# 4. use techniques such as data augmentation, learning rate decay and dropout to increase our model's accuracy \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## with applications to Garbage Sorting "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # linear algebra \n",
    "import pandas as pd # data processing \n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2  # image processing package\n",
    "# keras for model\n",
    "import keras\n",
    "from keras.layers import Conv2D, MaxPool2D, Dropout, Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "from sklearn.utils import shuffle\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is where all the images are stored\n",
    "# users need to change the file path here \n",
    "# under this file path, we have four folders, each will have a category for garbage sorting \n",
    "# put images under corresponding folder \n",
    "train_dir = \"../yzheng070/Desktop/seg_train\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define how many classes we have \n",
    "classes = ['dry', 'wet', 'hazardous', 'recycle']\n",
    "len(classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read image and visualize some here \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read image and visualize some here \n",
    "one_from_each = []\n",
    "titles = []\n",
    "classes = os.listdir(train_dir)\n",
    "n_classes = len(classes)\n",
    "for x in classes:\n",
    "    unique_img_dir = train_dir + '/' + x\n",
    "    temp_directory = os.listdir(unique_img_dir)\n",
    "    temp_img = unique_img_dir + '/' + temp_directory[random.randint(1,10)]\n",
    "    image = cv2.imread(temp_img)\n",
    "    image = np.array(image)\n",
    "    image = image.astype('float32')/255.0\n",
    "    one_from_each.append(image)\n",
    "    titles.append(x)\n",
    "    \n",
    "for i in range(5):\n",
    "    imageshow = one_from_each[i]\n",
    "    plt.imshow(imageshow[:,:,::-1])\n",
    "    plt.title(titles[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define labels \n",
    "print(classes)\n",
    "labels_dict = {0:classes[0],\n",
    "               1:classes[1],\n",
    "               2:classes[2],\n",
    "               3:classes[3]\n",
    "               }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a load data function \n",
    "# to process it for modeling \n",
    "\n",
    "def load_data(directory):\n",
    "    size = 150,150\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    for folder in os.listdir(directory):\n",
    "        print(\"Loading images from : \",folder, \": \", end=\"\")\n",
    "        for file in os.listdir(directory + \"/\" + folder):\n",
    "            img_path = directory + \"/\" + folder + \"/\" + file\n",
    "            curr_img = cv2.imread(img_path)\n",
    "            curr_img = cv2.resize(curr_img, size)\n",
    "            images.append(curr_img)\n",
    "            if folder == labels_dict[0]:\n",
    "                current_label = 0\n",
    "            elif folder == labels_dict[1]:\n",
    "                current_label = 1\n",
    "            elif folder == labels_dict[2]:\n",
    "                current_label = 2\n",
    "            elif folder == labels_dict[3]:\n",
    "                current_label = 3\n",
    "         \n",
    "            labels.append(current_label)\n",
    "        print(\"completed\")\n",
    "    \n",
    "    images, labels = shuffle(images, labels)\n",
    "    \n",
    "    images = np.array(images)\n",
    "    images = images.astype('float32')/255.0\n",
    "    labels = np.array(labels)\n",
    "    labels = keras.utils.to_categorical(labels, n_classes)\n",
    "    \n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = load_data(train_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modeling \n",
    "# using CNN \n",
    "# Convolutional Neural Network  \n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size =[5,5], strides = 2, activation = 'relu', input_shape = (150,150,3)))\n",
    "model.add(MaxPool2D(pool_size = [2,2], strides = 2))\n",
    "model.add(Conv2D(64, kernel_size = [3,3], padding = 'same', activation = \"relu\"))\n",
    "model.add(Conv2D(64, kernel_size = [3,3], padding = 'same', activation = \"relu\"))\n",
    "model.add(MaxPool2D(pool_size = [2,2], strides = 2))\n",
    "model.add(Conv2D(128, kernel_size = [3,3], activation = \"relu\"))\n",
    "model.add(Conv2D(128, kernel_size = [3,3], activation = \"relu\"))\n",
    "model.add(MaxPool2D(pool_size = [2,2], strides = 2))\n",
    "model.add(Conv2D(256, kernel_size = [3,3], activation = \"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation = 'relu'))\n",
    "model.add(Dense(n_classes, activation = 'softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model validation\n",
    "model.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n",
    "model_hist =  model.fit(X_train, Y_train, epochs = 10, validation_split = 0.1, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the accuracy \n",
    "plt.plot(model_hist.history['acc'])\n",
    "plt.plot(model_hist.history['val_acc'])\n",
    "plt.title(\"training vs Validation accuracy\")\n",
    "plt.legend(['train acc.','validation acc.'], loc = 'lower right')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(model_hist.history['loss'])\n",
    "plt.plot(model_hist.history['val_loss'])\n",
    "plt.title(\"Loss plot (train vs validation)\")\n",
    "plt.legend(['training loss','validation loss'], loc = 'upper right')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data\n",
    "# put model on test data to check results \n",
    "\n",
    "# get test data \n",
    "# users need to change to your path \n",
    "test_dir = \"../yzheng070/Desktop/seg_test\"\n",
    "\n",
    "X_test, Y_test = load_data(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get accuracy on test data \n",
    "metrics = model.evaluate(X_test, Y_test)\n",
    "print(\"Model metrics = \",model.metrics_names)\n",
    "print(\"Testing Accuracy = \", metrics[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
